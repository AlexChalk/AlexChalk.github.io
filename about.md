---
title: About
layout: page
---
![Profile Image]({% if site.external-image %}{{ site.picture }}{% else %}{{ site.url }}/{{ site.picture }}{% endif %})

### About Me

I'm a graduate student, departmental scholar, Joubin-Selig Scholar, and Ontario Graduate Scholar in International Affairs at [Carleton](https://carleton.ca/npsia/). My goal is to contribute to government policy on AI.

I received analytical training in philosophy at Oxford (First Class Honours), and I gained technical knowledge from five years working as a programmer at tech startups. I value effective communication and interdisciplinarity.

I am fluent in Python, and I'm working through fast.ai's resources on [Practical Deep Learning](https://course.fast.ai/). I have completed a previous iteration of [Machine Learning](https://www.coursera.org/specializations/machine-learning-introduction) with Andrew Ng, and I've done a deep-dive into the transformer architectures used by large language models (LLMs) like ChatGPT. I have also spent time with researchers at [Mila](https://mila.quebec/) (informally), and I remain in touch with the institution.

I am interested in improving communication between machine learning researchers and policymakers. For example, I suspect that both lack of understanding in current technical research and implications of the rate of progress in AI could be better communicated to governments by researchers.

For policymakers, I believe that some grasp of how neural networks are trained is helpful to understand the ways they may not act as intended, and that this understanding is crucial to many, perhaps most, major decisions regarding AI that government will face. I also believe governments require sufficient technical know-how to critically assess researchers' opinions and to form their own conclusions.

I'm currently researching technical misconceptions/omissions in government materials on AI. I'm also interested in public policy that would prepare governments to act quickly in response to an AI-related crisis.

If in doubt, please send me a message.

n.b.1. A list of sources I recommend for learning about transformers: the [original paper](https://arxiv.org/abs/1706.03762); [this blog series by Ben Levinstein](https://benlevinstein.substack.com/p/a-conceptual-guide-to-transformers?sd=pf) for a high-level, non-technical overview; and Chapters 1 and 3 of *Natural Language Processing with Transformers* (Tunstall et al.) for a technical deep-dive.

n.b.2. I don't use social media, so this website is one of the only ways people from my past can reconnect with me. In the interests of showing up when they search for me on the internet, here are some places I've been: International Guitar Festival (IGF), St Bartholomew's School in Newbury (St Bart's), The Catweazle Club, Mansfield College, Oxford University, Busbud, Procurify, the Choir of the Church of St. Andrew and St. Paul (A&P).
